{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabsrcha/Gabrielly_PIBIC_Lung.Node.Segmentation/blob/main/C%C3%B3pia_de_Gabs_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HmCO84iA_eJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a9264e-f6ac-446f-a601-6dacf23c09c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.9.0 torchmetrics-1.2.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torch import randint\n",
        "!pip install torchmetrics\n",
        "from torchmetrics.classification import Dice\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "BofPs4Wg-_mk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EDEj-TtPBX9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b52365fd-85b0-429e-80d9-026fbd6191da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 103MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn()\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features , 2)\n",
        "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "hidden_layer = 256\n",
        "model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask , hidden_layer , 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BJEOmR60BgUC"
      },
      "outputs": [],
      "source": [
        "transform = T.ToTensor()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eAA6olgjz-R",
        "outputId": "d7403e40-5611-4f3f-fd24-c530dd4a99b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Nprx8K6jBkR7"
      },
      "outputs": [],
      "source": [
        "train_images = sorted(os.listdir(\"/content/drive/MyDrive/Gabs_lung/train/images/\"))\n",
        "train_mask = sorted(os.listdir(\"/content/drive/MyDrive/Gabs_lung/train/mask/\"))\n",
        "train_imgs = np.array(train_images)\n",
        "train_masks = np.array(train_mask)\n",
        "\n",
        "\n",
        "valid_images = sorted(os.listdir(\"/content/drive/MyDrive/Gabs_lung/valid/images/\"))\n",
        "valid_mask = sorted(os.listdir(\"/content/drive/MyDrive/Gabs_lung/valid/mask/\"))\n",
        "val_imgs = np.array(valid_images)\n",
        "val_masks = np.array(valid_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xcbknRu1B44t"
      },
      "outputs": [],
      "source": [
        "def custom_collate(data):\n",
        "#   data = [d for d in data if d[1][\"boxes\"].shape[0] > 0]\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x87wntIqB138",
        "outputId": "eca3be34-a718-4633-c4c1-23659b5b52b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaskRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
              "    )\n",
              "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
              "    (mask_head): MaskRCNNHeads(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (mask_predictor): MaskRCNNPredictor(\n",
              "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (mask_fcn_logits): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FNhcFoueCTPG"
      },
      "outputs": [],
      "source": [
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "#criterion = nn.L1Loss.to(device)\n",
        "#optimizer = torch.optim.SGD(params, lr=0.0001, momentum=0.9, weight_decay=0.005)\n",
        "\n",
        "optimizer = torch.optim.Adam(params, lr=0.0001, weight_decay=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qLegnnUr_1eF"
      },
      "outputs": [],
      "source": [
        "class CustDat(torch.utils.data.Dataset):\n",
        "    def __init__(self , images , masks):\n",
        "        self.imgs = images\n",
        "        self.masks = masks\n",
        "\n",
        "    def __getitem__(self , idx):\n",
        "        img = Image.open(\"/content/drive/MyDrive/Gabs_lung/train/images/\" + self.imgs[idx]).convert(\"RGB\")\n",
        "        mask = Image.open(\"/content/drive/MyDrive/Gabs_lung/train/mask/\" + self.masks[idx])\n",
        "        mask = np.array(mask)\n",
        "        obj_ids = np.unique(mask)\n",
        "        obj_ids = obj_ids[1:]\n",
        "        num_objs = len(obj_ids)\n",
        "        masks = np.zeros((num_objs , mask.shape[0] , mask.shape[1]))\n",
        "        #print(np.where(mask > np.min(mask)))\n",
        "        for i in range(num_objs):\n",
        "            #masks[i][mask == i+1] = True\n",
        "            masks[i][mask > 0] = True\n",
        "        boxes = []\n",
        "        for i in range(num_objs):\n",
        "            pos = np.where(masks[i])\n",
        "            xmin = np.min(pos[1])\n",
        "            xmax = np.max(pos[1])\n",
        "            ymin = np.min(pos[0])\n",
        "            ymax = np.max(pos[0])\n",
        "            boxes.append([xmin , ymin , xmax , ymax])\n",
        "        boxes = torch.as_tensor(boxes , dtype = torch.float32)\n",
        "        labels = torch.ones((num_objs,) , dtype = torch.int64)\n",
        "        masks = torch.as_tensor(masks , dtype = torch.uint8)\n",
        "        #print(boxes)\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"masks\"] = masks\n",
        "        return T.ToTensor()(img) , target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "\n",
        "class CustDatVal(torch.utils.data.Dataset):\n",
        "    def __init__(self , images , masks):\n",
        "        self.imgs = images\n",
        "        self.masks = masks\n",
        "\n",
        "    def __getitem__(self , idx):\n",
        "        img = Image.open(\"/content/drive/MyDrive/Gabs_lung/valid/images/\" + self.imgs[idx]).convert(\"RGB\")\n",
        "        mask = Image.open(\"/content/drive/MyDrive/Gabs_lung/valid/mask/\" + self.masks[idx])\n",
        "        mask = np.array(mask)\n",
        "        obj_ids = np.unique(mask)\n",
        "        obj_ids = obj_ids[1:]\n",
        "        num_objs = len(obj_ids)\n",
        "        masks = np.zeros((num_objs , mask.shape[0] , mask.shape[1]))\n",
        "        for i in range(num_objs):\n",
        "            #masks[i][mask == i+1] = True\n",
        "            masks[i][mask > 0] = True\n",
        "        boxes = []\n",
        "        for i in range(num_objs):\n",
        "            pos = np.where(masks[i])\n",
        "            xmin = np.min(pos[1])\n",
        "            xmax = np.max(pos[1])\n",
        "            ymin = np.min(pos[0])\n",
        "            ymax = np.max(pos[0])\n",
        "            boxes.append([xmin , ymin , xmax , ymax])\n",
        "        boxes = torch.as_tensor(boxes , dtype = torch.float32)\n",
        "        labels = torch.ones((num_objs,) , dtype = torch.int64)\n",
        "        masks = torch.as_tensor(masks , dtype = torch.uint8)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"masks\"] = masks\n",
        "        return T.ToTensor()(img) , target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GK0esaAqBnHu"
      },
      "outputs": [],
      "source": [
        "train_dl = torch.utils.data.DataLoader(CustDat(train_imgs , train_masks),\n",
        "                                 batch_size = 100,\n",
        "                                 shuffle = True ,\n",
        "                                 collate_fn = custom_collate ,\n",
        "                                 num_workers = 1 ,\n",
        "                                 pin_memory = True if torch.cuda.is_available() else False)\n",
        "\n",
        "val_dl = torch.utils.data.DataLoader(CustDatVal(val_imgs , val_masks) ,\n",
        "                                 batch_size = 51,\n",
        "                                 shuffle = True ,\n",
        "                                 collate_fn = custom_collate ,\n",
        "                                 num_workers = 1 ,\n",
        "                                 pin_memory = True if torch.cuda.is_available() else False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(enumerate(train_dl))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4hF9t9Wto3Z",
        "outputId": "4999158a-5590-4f01-9b39-f01c334d69ad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<enumerate object at 0x7bad56c49800>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQgeKUtgCd_2",
        "outputId": "0c2ab918-566f-441d-e4d2-4a0bf6a1684f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss_classifier': tensor(0.7294, grad_fn=<NllLossBackward0>), 'loss_box_reg': tensor(0.0001, grad_fn=<DivBackward0>), 'loss_mask': tensor(1.2687, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'loss_objectness': tensor(0.6965, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'loss_rpn_box_reg': tensor(0.0011, grad_fn=<DivBackward0>)}\n",
            "0    4.498820900917053    2.1282553672790527\n",
            "1    4.559898614883423    1.392319679260254\n",
            "2    2.7249547243118286    1.4161605834960938\n",
            "3    2.4741194248199463    1.1204700469970703\n",
            "4    2.0425443053245544    1.526381492614746\n",
            "5    1.9102196097373962    1.083957552909851\n",
            "6    2.77347195148468    1.2170971632003784\n",
            "7    2.0741308331489563    0.8001686930656433\n",
            "8    1.6201080083847046    0.8185805678367615\n",
            "9    1.317038893699646    0.995917558670044\n",
            "10    2.0749118328094482    0.896856427192688\n",
            "11    1.822017788887024    0.8770217895507812\n",
            "12    1.605968952178955    0.7595527172088623\n",
            "13    1.6203755140304565    0.7790910005569458\n",
            "14    1.4087591767311096    0.661304235458374\n",
            "15    1.5401865243911743    0.7807048559188843\n",
            "16    1.4458047151565552    0.8677263855934143\n",
            "17    1.5831871628761292    0.8337182402610779\n",
            "18    1.071161150932312    0.7397378087043762\n",
            "19    1.3816425800323486    1.057998538017273\n",
            "20    1.4565829634666443    0.6725448369979858\n",
            "21    1.1439313292503357    0.6910613179206848\n",
            "22    1.5361645817756653    0.5990826487541199\n",
            "23    1.346621811389923    0.694726824760437\n",
            "24    1.4556362628936768    0.6288114190101624\n",
            "25    1.3869993686676025    0.7260841727256775\n",
            "26    1.221594899892807    0.614406943321228\n",
            "27    1.3876678347587585    0.6988604664802551\n",
            "28    1.500850796699524    0.670343816280365\n",
            "29    1.2562741041183472    0.7982105016708374\n",
            "30    1.158743143081665    0.5850790739059448\n",
            "31    1.0982697010040283    0.5975505113601685\n",
            "32    1.1337186992168427    0.4081762731075287\n",
            "33    1.54477196931839    1.021275520324707\n",
            "34    1.3121634721755981    0.527957558631897\n",
            "35    1.5106754899024963    0.8969742655754089\n",
            "36    1.1651804447174072    0.7205228209495544\n",
            "37    1.1948635578155518    0.9533829689025879\n",
            "38    1.2444807291030884    0.5371100306510925\n",
            "39    1.2195650935173035    0.6417880654335022\n",
            "40    1.1582711338996887    0.5017451047897339\n",
            "41    1.3168213367462158    0.659412145614624\n",
            "42    1.1587917804718018    0.6473313570022583\n",
            "43    1.2082398533821106    0.5918186902999878\n",
            "44    1.2868261933326721    0.45333224534988403\n",
            "45    1.1826674342155457    0.9875994324684143\n",
            "46    1.5089299082756042    0.6684471368789673\n",
            "47    1.3533693552017212    0.5908052325248718\n",
            "48    1.2983927130699158    1.0015133619308472\n",
            "49    1.039565622806549    1.023572325706482\n",
            "50    1.5366244316101074    0.5764256119728088\n",
            "51    0.9833110570907593    0.8379687070846558\n",
            "52    1.2699374556541443    0.5173510313034058\n",
            "53    1.070260763168335    0.5889981985092163\n",
            "54    1.1130042970180511    0.44311222434043884\n",
            "55    1.2318462133407593    0.5968124866485596\n",
            "56    1.4352349638938904    0.5548954010009766\n",
            "57    1.0606869459152222    0.5871757864952087\n",
            "58    1.4438670873641968    0.6697180271148682\n",
            "59    1.0759207904338837    0.620434045791626\n",
            "60    1.251401275396347    0.5166128873825073\n",
            "61    1.1512871980667114    0.6462845802307129\n",
            "62    1.3656451106071472    0.7072988748550415\n",
            "63    1.2203981280326843    0.751935601234436\n",
            "64    1.2602717280387878    0.5710122585296631\n",
            "65    1.1611931324005127    0.595397412776947\n",
            "66    1.1034939289093018    0.8524359464645386\n",
            "67    1.1469365954399109    0.574345588684082\n",
            "68    1.09503573179245    0.6713504195213318\n",
            "69    1.1519455909729004    0.9605738520622253\n",
            "70    1.0081530809402466    0.4440351724624634\n",
            "71    1.052623450756073    0.8943961262702942\n",
            "72    0.9112803637981415    0.5729241371154785\n",
            "73    0.7919013500213623    0.7354933619499207\n",
            "74    1.6439979076385498    0.7155919671058655\n",
            "75    1.3309878706932068    0.539705216884613\n",
            "76    1.0743990540504456    0.7222267389297485\n",
            "77    0.9237627983093262    0.7487557530403137\n",
            "78    1.057003676891327    0.6324821710586548\n",
            "79    1.2381511628627777    0.5757241249084473\n",
            "80    1.1751567721366882    0.8422395586967468\n",
            "81    1.2421839237213135    0.4765852391719818\n",
            "82    1.2308057844638824    0.7645358443260193\n",
            "83    1.4949438571929932    0.7783812880516052\n",
            "84    1.344605028629303    0.8636704087257385\n",
            "85    1.0436593294143677    0.8280532956123352\n",
            "86    1.0688483119010925    0.7167425751686096\n",
            "87    1.3127970099449158    0.6505565643310547\n",
            "88    1.604580819606781    0.6780726909637451\n",
            "89    1.146990954875946    0.8086292743682861\n",
            "90    1.0929391384124756    0.7407722473144531\n",
            "91    1.1214128732681274    0.7671157121658325\n",
            "92    0.9925358295440674    0.685932457447052\n",
            "93    0.9863699376583099    0.8995287418365479\n",
            "94    1.1721304059028625    1.1384786367416382\n",
            "95    1.010287195444107    0.4653639495372772\n",
            "96    1.125649780035019    0.4920964241027832\n",
            "97    1.363832175731659    0.7539541721343994\n",
            "98    1.1201621294021606    0.8360830545425415\n",
            "99    0.838664323091507    1.0237278938293457\n",
            "100    0.8958345055580139    0.7728084325790405\n",
            "101    1.1849629282951355    0.5211935639381409\n",
            "102    1.0712949633598328    0.5098567008972168\n",
            "103    1.3554767370224    0.9574911594390869\n",
            "104    1.0742087364196777    0.6753136515617371\n",
            "105    1.187073528766632    0.5987213253974915\n",
            "106    1.3690094947814941    0.8300789594650269\n",
            "107    0.8362033069133759    0.7330900430679321\n",
            "108    1.0693552792072296    0.9996124505996704\n",
            "109    0.8928409814834595    0.701477587223053\n",
            "110    0.9654070138931274    0.9508193135261536\n",
            "111    1.1156262755393982    0.9026647210121155\n",
            "112    1.1996151208877563    1.089486837387085\n",
            "113    0.8911829888820648    0.8581215143203735\n",
            "114    0.7255219519138336    0.6650634407997131\n",
            "115    1.0790629386901855    1.1336873769760132\n",
            "116    0.9804300367832184    0.9230092167854309\n",
            "117    0.9781552255153656    0.6803670525550842\n",
            "118    1.6514847874641418    0.4712381958961487\n",
            "119    0.8805669844150543    0.8811187148094177\n",
            "120    1.030932068824768    1.0123950242996216\n",
            "121    0.8965018093585968    0.583572268486023\n",
            "122    1.0836657285690308    0.7236478328704834\n",
            "123    0.9372676908969879    0.718012273311615\n",
            "124    0.9340524077415466    0.43386372923851013\n",
            "125    1.1189925968647003    0.4965359568595886\n",
            "126    0.9711503982543945    0.7524687051773071\n",
            "127    0.9881369173526764    0.6924617886543274\n",
            "128    0.8595284223556519    0.7309910655021667\n",
            "129    0.7999853491783142    0.8212569952011108\n",
            "130    0.9978933036327362    0.4881665110588074\n",
            "131    1.003278225660324    0.6106154918670654\n",
            "132    1.2633119821548462    1.2588183879852295\n",
            "133    0.901747077703476    0.9504055976867676\n",
            "134    0.858320564031601    0.6072803735733032\n",
            "135    0.9827730357646942    0.7483749985694885\n",
            "136    0.8876646757125854    0.7858609557151794\n",
            "137    0.9695799946784973    0.6275885105133057\n",
            "138    0.7672405540943146    0.4339449405670166\n",
            "139    0.7432534992694855    0.6284165382385254\n",
            "140    0.8767999708652496    0.2776069641113281\n",
            "141    1.2313148081302643    0.4274485409259796\n",
            "142    0.746126800775528    0.6707845330238342\n",
            "143    0.9321326613426208    0.6822242140769958\n",
            "144    0.7976255118846893    1.2172045707702637\n",
            "145    1.1833258867263794    0.44334858655929565\n",
            "146    0.7968099415302277    0.5249123573303223\n",
            "147    0.7200694382190704    0.6008689403533936\n",
            "148    0.8766575753688812    0.5202159881591797\n",
            "149    0.8791019022464752    0.8070084452629089\n",
            "150    0.998028427362442    0.5935788154602051\n",
            "151    1.0749703347682953    0.6919470429420471\n",
            "152    1.1232828497886658    0.7140215635299683\n",
            "153    0.9107324481010437    0.6965203881263733\n",
            "154    0.7510627508163452    0.5500480532646179\n",
            "155    1.119011640548706    1.6299495697021484\n",
            "156    0.7112219035625458    1.0806169509887695\n",
            "157    0.9695906937122345    1.0990533828735352\n",
            "158    1.2671102285385132    1.1740018129348755\n",
            "159    0.7997025847434998    0.48061051964759827\n",
            "160    0.9265023767948151    0.5190243124961853\n",
            "161    0.9464635848999023    0.6043317317962646\n",
            "162    0.9297023713588715    0.5217036008834839\n",
            "163    0.7211511433124542    1.0961495637893677\n",
            "164    0.8102023601531982    0.5169702768325806\n",
            "165    1.0448864102363586    0.7249788641929626\n",
            "166    0.6322703659534454    1.0442957878112793\n",
            "167    0.8691271543502808    1.0812742710113525\n",
            "168    0.9281576871871948    0.8622254133224487\n",
            "169    0.7216610610485077    0.8102684020996094\n",
            "170    0.921582967042923    0.9339088797569275\n",
            "171    0.7024436295032501    0.862546443939209\n",
            "172    0.8598445355892181    0.7000622749328613\n",
            "173    0.6371640861034393    0.46320587396621704\n",
            "174    0.7497863173484802    0.6378200054168701\n",
            "175    0.9768820405006409    0.6573432087898254\n",
            "176    0.7769937813282013    0.8640527725219727\n",
            "177    0.7204625010490417    1.2720202207565308\n",
            "178    1.0088369250297546    1.3590188026428223\n",
            "179    0.9123757481575012    0.4112812876701355\n",
            "180    0.7560227811336517    0.7997957468032837\n",
            "181    0.7910492420196533    0.5113120079040527\n",
            "182    0.9458452463150024    0.8639197945594788\n",
            "183    0.7323844134807587    0.8428835272789001\n",
            "184    1.014741063117981    0.5930380821228027\n",
            "185    0.7707352042198181    1.1452937126159668\n",
            "186    0.7541100978851318    0.6137564182281494\n",
            "187    0.7480653524398804    0.8622034788131714\n",
            "188    0.8789544403553009    0.6836062669754028\n",
            "189    0.9569990336894989    0.44037678837776184\n",
            "190    1.0334149301052094    0.4150818884372711\n",
            "191    1.1251414716243744    0.7865698337554932\n",
            "192    0.679201066493988    0.5139925479888916\n",
            "193    0.7715390920639038    0.5077993273735046\n",
            "194    0.6371850967407227    0.5785147547721863\n",
            "195    0.7558179497718811    0.6701753735542297\n",
            "196    0.7727402448654175    0.8810327053070068\n",
            "197    0.8102381527423859    0.6886156797409058\n",
            "198    0.7304216027259827    1.39240300655365\n",
            "199    0.815025269985199    1.1374861001968384\n",
            "200    0.8813275396823883    0.30548885464668274\n",
            "201    0.7014378607273102    1.1935960054397583\n",
            "202    0.7233182191848755    0.7395060658454895\n",
            "203    0.684912383556366    0.9723560214042664\n",
            "204    0.8345573842525482    1.0959219932556152\n",
            "205    0.849636971950531    0.4609198570251465\n",
            "206    0.5522301495075226    0.7542752623558044\n",
            "207    0.7514437735080719    0.49103865027427673\n",
            "208    0.8460307419300079    1.0890315771102905\n",
            "209    0.5941063761711121    0.8537591695785522\n",
            "210    0.6508199870586395    0.3078782856464386\n",
            "211    0.672824889421463    2.089599847793579\n",
            "212    1.7509635090827942    0.6728107333183289\n",
            "213    0.8155481517314911    0.6211633086204529\n",
            "214    0.7650690674781799    0.710337221622467\n",
            "215    0.7367309033870697    0.39170220494270325\n",
            "216    1.0437270104885101    0.6481135487556458\n",
            "217    0.936246931552887    0.7962704300880432\n",
            "218    0.7510365545749664    0.6586106419563293\n",
            "219    0.8688643276691437    0.4703729450702667\n",
            "220    0.76031294465065    0.785181999206543\n",
            "221    1.271771252155304    0.8205282092094421\n",
            "222    0.9234193861484528    0.38079285621643066\n",
            "223    0.7563543021678925    0.4881599545478821\n",
            "224    0.8088648021221161    0.5632990598678589\n",
            "225    0.659195601940155    0.684782087802887\n",
            "226    0.8192050158977509    1.0062435865402222\n",
            "227    0.8600141406059265    0.8225014805793762\n",
            "228    0.9280222356319427    0.763366162776947\n",
            "229    1.2416186332702637    0.5700460076332092\n",
            "230    0.6739327311515808    0.42595478892326355\n",
            "231    0.8333926796913147    0.44360992312431335\n",
            "232    0.7780458033084869    1.0778430700302124\n",
            "233    1.2248332500457764    0.6225658059120178\n",
            "234    0.8601976931095123    1.3740414381027222\n",
            "235    0.7362591922283173    1.561472773551941\n",
            "236    0.9996321499347687    0.8170678615570068\n",
            "237    0.7607586681842804    0.6536122560501099\n",
            "238    0.7367412149906158    1.5448161363601685\n",
            "239    0.7705721855163574    0.9857046008110046\n",
            "240    0.7959812879562378    1.40495765209198\n",
            "241    0.650985985994339    0.861550509929657\n",
            "242    0.6073645949363708    0.5051391124725342\n",
            "243    0.7109789252281189    1.1395643949508667\n",
            "244    0.6602634191513062    0.49187344312667847\n",
            "245    0.7204059660434723    1.3216618299484253\n",
            "246    0.758890300989151    1.0071513652801514\n",
            "247    0.9798856973648071    0.8804885745048523\n",
            "248    0.7509832382202148    0.39459356665611267\n",
            "249    0.6163005530834198    0.630783200263977\n",
            "250    0.8860658407211304    1.0060858726501465\n",
            "251    0.5870538651943207    0.4225137531757355\n",
            "252    0.6578622758388519    0.7253260016441345\n",
            "253    0.6204935014247894    1.1152842044830322\n",
            "254    0.5625813603401184    1.055723786354065\n",
            "255    0.6313311755657196    1.092833161354065\n",
            "256    0.7738018929958344    0.3779389560222626\n",
            "257    0.6351867616176605    0.808896541595459\n",
            "258    0.7292616069316864    1.8082016706466675\n",
            "259    0.6364441215991974    0.854548454284668\n",
            "260    0.7602644562721252    0.5922648906707764\n",
            "261    0.9424611926078796    1.1810799837112427\n",
            "262    0.9222738146781921    0.39706912636756897\n",
            "263    1.1315075159072876    0.43231648206710815\n",
            "264    0.7745219767093658    0.5894541144371033\n"
          ]
        }
      ],
      "source": [
        "#train_dl = torch.utils.data.DataLoader(CustDat(train_imgs , train_masks))\n",
        "#val_dl = torch.utils.data.DataLoader(CustDatVal(val_imgs , val_masks))\n",
        "\n",
        "all_train_losses = []\n",
        "all_val_losses = []\n",
        "flag = False\n",
        "for epoch in range(600):\n",
        "    #print(epoch)\n",
        "    train_epoch_loss = 0\n",
        "    val_epoch_loss = 0\n",
        "    model.train()\n",
        "    for i , dt in enumerate(train_dl):\n",
        "        if len(dt) <= 1:\n",
        "            print(\"++++\",i)\n",
        "            continue\n",
        "        imgs = [dt[0][0].to(device) , dt[1][0].to(device)]\n",
        "        targ = [dt[0][1] , dt[1][1]]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targ]\n",
        "        loss = model(imgs , targets)\n",
        "        if not flag:\n",
        "            print(loss)\n",
        "            flag = True\n",
        "        losses = sum([l for l in loss.values()])\n",
        "        train_epoch_loss += losses.cpu().detach().numpy()\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "    all_train_losses.append(train_epoch_loss)\n",
        "    with torch.no_grad():\n",
        "        for j , dt in enumerate(val_dl):\n",
        "            imgs = [dt[0][0].to(device) , dt[1][0].to(device)]\n",
        "            targ = [dt[0][1] , dt[1][1]]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targ]\n",
        "            loss = model(imgs , targets)\n",
        "            losses = sum([l for l in loss.values()])\n",
        "            val_epoch_loss += losses.cpu().detach().numpy()\n",
        "        all_val_losses.append(val_epoch_loss)\n",
        "    print(epoch , \"  \" , train_epoch_loss , \"  \" , val_epoch_loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2V47fNhytfIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 9))\n",
        "plt.plot(all_train_losses, label='Train')\n",
        "plt.plot(all_val_losses, label='Test', alpha=0.5)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.title('Convergence', fontsize=16)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ggTn9mTKtoGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmd_MXThCjCV"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Gabs_lung/modelgabs6.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = sorted(os.listdir(\"/content/drive/MyDrive/Gabs_lung/general/images/\"))"
      ],
      "metadata": {
        "id": "Yh2NrD4RqbLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Gabs_lung/modelgabs6.pt'))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "Zb69ouqAMJsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example plotting multiple values\n",
        "metric = Dice()\n",
        "values = [ ]\n",
        "for _ in range(100):\n",
        "  values.append(metric(randint(2,(10,)), randint(2,(10,))))\n",
        "fig_, ax_ = metric.plot(values)"
      ],
      "metadata": {
        "id": "fEAaNGRB04yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.detection import image_list\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "#criterion = nn.CrossEntropyLoss.to(device)\n",
        "l=0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "#while (l<61):\n",
        "#for l in range(1,len(images)):\n",
        "f = plt.figure()\n",
        "all_test_losses = []\n",
        "for l in images:\n",
        "    print(l)\n",
        "    img = Image.open(\"/content/drive/MyDrive/Gabs_lung/general/images/\"+str(l))\n",
        "    mask = Image.open(\"/content/drive/MyDrive/Gabs_lung/general/mask/\"+str(l))\n",
        "    transform = T.ToTensor()\n",
        "    ig = transform(img)\n",
        "    with torch.no_grad():\n",
        "        pred = model([ig.to(device)])\n",
        "        try:\n",
        "          pred1 = (pred[0][\"masks\"][0].cpu())\n",
        "          # Converte as máscaras para arrays numpy\n",
        "          pred_mask = (pred[0][\"masks\"][0].cpu().numpy() > 0).astype(int)\n",
        "          true_mask = (np.array(mask) > 0).astype(int)\n",
        "          loss = nn.CrossEntropyLoss(pred_mask, true_mask)\n",
        "          all_test_losses.append(loss.cpu.data)\n",
        "\n",
        "          # Calcula o valor Dice\n",
        "          dice_metric = torchmetrics.classification.Dice()\n",
        "          dice_value = dice_metric(torch.from_numpy(pred_mask), torch.from_numpy(true_mask))\n",
        "          print(f\"Valor Dice: {dice_value.item()}\")\n",
        "\n",
        "          # Calcula a acurácia\n",
        "          accuracy = accuracy_score(true_mask.flatten(), pred_mask.flatten())\n",
        "          print(f\"Acurácia: {accuracy}\")\n",
        "          #plt.imshow((pred[0][\"masks\"][0].cpu().detach().numpy()*255).astype(\"uint8\").squeeze(), cmap='gray')\n",
        "\n",
        "          # # Subplot para a máscara\n",
        "          plt.subplot(1, 3, 1)\n",
        "          plt.imshow((pred[0][\"masks\"][0].cpu().detach().numpy() * 255).astype(\"uint8\").squeeze(), cmap='gray')\n",
        "          plt.axis('off')\n",
        "          plt.title(\"Máscara\")\n",
        "\n",
        "          # # Subplot para a imagem original\n",
        "          plt.subplot(1, 3, 2)\n",
        "          plt.imshow(mask)\n",
        "          plt.axis('off')\n",
        "          plt.title(\"Máscara Original\")\n",
        "\n",
        "          # # Subplot para a imagem original\n",
        "          plt.subplot(1, 3, 3)\n",
        "          plt.imshow(img)\n",
        "          plt.axis('off')\n",
        "          plt.title(\"Imagem Original\")\n",
        "\n",
        "          #plt.savefig(\"/content/drive/MyDrive/Gabs_lung/test6/\"+str(l), format='png', bbox_inches='tight',pad_inches=0)\n",
        "          plt.clf()\n",
        "        except IndexError:\n",
        "            pass\n",
        "epoch_loss = np.asarray(epoch_loss)"
      ],
      "metadata": {
        "id": "9f4RdgYLJ8CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import torchmetrics\n",
        "import numpy as np\n",
        "\n",
        "# ...\n",
        "\n",
        "# Após a geração das máscaras pelo modelo\n",
        "with torch.no_grad():\n",
        "    pred = model([ig.to(device)])\n",
        "    try:\n",
        "        # Converte as máscaras para arrays numpy\n",
        "        pred_mask = (pred[0][\"masks\"][0].cpu().numpy() > 0).astype(int)\n",
        "        true_mask = (np.array(mask) > 0).astype(int)\n",
        "\n",
        "        # Calcula o valor Dice\n",
        "        dice_metric = torchmetrics.classification.Dice()\n",
        "        dice_value = dice_metric(torch.from_numpy(pred_mask), torch.from_numpy(true_mask))\n",
        "        print(f\"Valor Dice: {dice_value.item()}\")\n",
        "\n",
        "        # Calcula a acurácia\n",
        "        accuracy = accuracy_score(true_mask.flatten(), pred_mask.flatten())\n",
        "        print(f\"Acurácia: {accuracy}\")\n",
        "\n",
        "        # Continua com a geração das imagens e outros processamentos\n",
        "    except IndexError:\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "3NWWIdqrDuSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3yZMUyGOEg96"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}